{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a46c89-989b-4968-bae3-a8a2a0e90ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e08ba7-4852-4110-a2fc-889c10e0b3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64249847-05da-4b1e-9340-f2d653d00b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 버전\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    angle_rads = np.zeros(angle_rads.shape)\n",
    "    angle_rads[:, 0::2] = sines\n",
    "    angle_rads[:, 1::2] = cosines\n",
    "    pos_encoding = tf.constant(angle_rads)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "    print(pos_encoding.shape)\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9707e7-17b4-4add-94d2-e8edf5195c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 스케일링\n",
    "  # dk의 루트값으로 나눠준다.\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7094d0-596c-4f20-b419-51aec2ade254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    # d_model을 num_heads로 나눈 값.\n",
    "    # 논문 기준 : 64\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # WO에 해당하는 밀집층 정의\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "    # q : (batch_size, query의 문장 길이, d_model)\n",
    "    # k : (batch_size, key의 문장 길이, d_model)\n",
    "    # v : (batch_size, value의 문장 길이, d_model)\n",
    "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 2. 헤드 나누기\n",
    "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 4. 헤드 연결(concatenate)하기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 5. WO에 해당하는 밀집층 지나기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6784fa7f-8e13-4225-92df-a181d49724c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, key의 문장 길이)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995d3558-fcb9-4d5f-8067-d47b7a29d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': padding_mask # 패딩 마스크 사용\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c49775-6b65-4b9b-9783-92149260af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@@@수정됨\n",
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 인코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1783b813-3f13-4870-9c43-4aceb49e5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a346a703-5a6d-48c1-9a6f-0836c067565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "  # 잔차 연결과 층 정규화\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546040fb-251d-4384-bc04-e27c39121f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 디코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431c3d36-e11e-424e-9ffc-4b4b9766a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "  # 인코더의 입력\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 디코더의 입력\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더의 패딩 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 디코더의 패딩 마스크(두번째 서브층)\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 다음 단어 예측을 위한 출력층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0820f78a-3b85-4121-a8fa-8e788b4e60b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 18:21:49.230823: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dafe7057-6365-444f-8445-ecb384d126a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc75c1e-31a9-477b-bb71-4df6bc02a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d1671-93ea-46cd-8b0d-4bed52992205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6d3ad6-2f59-4588-b4bb-375be4218864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1685a092-994f-43a1-8abe-ad1ebaea1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "\n",
    "# train_data = pd.read_csv('ChatBotData.csv')\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bf1a724-ea0b-4a23-8214-34971d862902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDX</th>\n",
       "      <th>발화자</th>\n",
       "      <th>발화문</th>\n",
       "      <th>카테고리</th>\n",
       "      <th>QA번호</th>\n",
       "      <th>QA여부</th>\n",
       "      <th>감성</th>\n",
       "      <th>인텐트</th>\n",
       "      <th>가격</th>\n",
       "      <th>수량</th>\n",
       "      <th>크기</th>\n",
       "      <th>장소</th>\n",
       "      <th>조직</th>\n",
       "      <th>사람</th>\n",
       "      <th>시간</th>\n",
       "      <th>날짜</th>\n",
       "      <th>상품명</th>\n",
       "      <th>상담번호</th>\n",
       "      <th>상담내순번</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>각각 두 번 주문, 결재하여 하나는 취소요청했어요 나머지 하나 주문만 발송되는 거 맞죠?</td>\n",
       "      <td>출산육아</td>\n",
       "      <td>157383</td>\n",
       "      <td>q</td>\n",
       "      <td>m</td>\n",
       "      <td>주문_취소_확인</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>s</td>\n",
       "      <td>주문해주신 리얼소프트 밴드 특대형 4팩 금일 오전 중 정상 출고된 것으로 확인됩니다.</td>\n",
       "      <td>출산육아</td>\n",
       "      <td>157383</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>주문_취소_확인</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>리얼소프트 밴드 특대형</td>\n",
       "      <td>157383</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>주문 취소 확인 안 됫는데 묘주문취소된 거 맞나요?</td>\n",
       "      <td>출산육아</td>\n",
       "      <td>92796</td>\n",
       "      <td>q</td>\n",
       "      <td>m</td>\n",
       "      <td>주문_취소_확인</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>네.잘못 간 주소로 반품요청을 해드렸는데요.</td>\n",
       "      <td>출산육아</td>\n",
       "      <td>92796</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>주문_취소_확인</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92796</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>c</td>\n",
       "      <td>방문 수령해 도 택배비 부담해야 되나요?</td>\n",
       "      <td>출산육아</td>\n",
       "      <td>135</td>\n",
       "      <td>q</td>\n",
       "      <td>m</td>\n",
       "      <td>배송_비용_질문</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDX 발화자                                                발화문  카테고리    QA번호  \\\n",
       "0    1   c  각각 두 번 주문, 결재하여 하나는 취소요청했어요 나머지 하나 주문만 발송되는 거 맞죠?  출산육아  157383   \n",
       "1    2   s    주문해주신 리얼소프트 밴드 특대형 4팩 금일 오전 중 정상 출고된 것으로 확인됩니다.  출산육아  157383   \n",
       "2    3   c                       주문 취소 확인 안 됫는데 묘주문취소된 거 맞나요?  출산육아   92796   \n",
       "3    4   s                           네.잘못 간 주소로 반품요청을 해드렸는데요.  출산육아   92796   \n",
       "4    5   c                             방문 수령해 도 택배비 부담해야 되나요?  출산육아     135   \n",
       "\n",
       "  QA여부 감성       인텐트   가격   수량   크기   장소   조직   사람   시간   날짜           상품명  \\\n",
       "0    q  m  주문_취소_확인  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN           NaN   \n",
       "1    a  m  주문_취소_확인  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  리얼소프트 밴드 특대형   \n",
       "2    q  m  주문_취소_확인  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN           NaN   \n",
       "3    a  m  주문_취소_확인  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN           NaN   \n",
       "4    q  m  배송_비용_질문  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN           NaN   \n",
       "\n",
       "     상담번호  상담내순번  \n",
       "0  157383      1  \n",
       "1  157383      2  \n",
       "2   92796      1  \n",
       "3   92796      2  \n",
       "4     135      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('출산육아_train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17034443-578f-4e4e-b1bd-5b2bbfd9d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 358712\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b4b0027-b286-4cb2-a3ff-0027a3e00bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX           0\n",
      "발화자           0\n",
      "발화문           0\n",
      "카테고리          0\n",
      "QA번호          0\n",
      "QA여부          0\n",
      "감성            0\n",
      "인텐트           0\n",
      "가격       355764\n",
      "수량       338702\n",
      "크기       337747\n",
      "장소       354067\n",
      "조직       352855\n",
      "사람       358222\n",
      "시간       353440\n",
      "날짜       322722\n",
      "상품명      238832\n",
      "상담번호          0\n",
      "상담내순번         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f0edfc0-b3ea-4474-b80d-7a743964a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "count = 0\n",
    "\n",
    "for sentence in train_data['발화문']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    if count % 2 == 0:\n",
    "        questions.append(sentence)\n",
    "    else:\n",
    "        answers.append(sentence)\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    if count > 20000:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbfb6ff4-7bcb-4a0f-8431-b6961677180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = []\n",
    "# for sentence in train_data['Q']:\n",
    "#     # 구두점에 대해서 띄어쓰기\n",
    "#     # ex) 12시 땡! -> 12시 땡 !\n",
    "#     sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "#     sentence = sentence.strip()\n",
    "#     questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc67e4ab-1372-4fc3-bafe-c72d3f2aba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers = []\n",
    "# for sentence in train_data['A']:\n",
    "#     # 구두점에 대해서 띄어쓰기\n",
    "#     # ex) 12시 땡! -> 12시 땡 !\n",
    "#     sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "#     sentence = sentence.strip()\n",
    "#     answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95947dac-a364-4d4f-bcf6-971568a56443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3b98605-02bf-4138-9b67-b9750757fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['각각 두 번 주문 ,  결재하여 하나는 취소요청했어요 나머지 하나 주문만 발송되는 거 맞죠 ?', '주문 취소 확인 안 됫는데 묘주문취소된 거 맞나요 ?', '방문 수령해 도 택배비 부담해야 되나요 ?', '프리미엄 상품평 남겼습니다 모빌대 보내주세요배송료는 착불인가요 ?', '제주도는 배송료가 어떻게 되나요 ?']\n",
      "['주문해주신 리얼소프트 밴드 특대형 4팩 금일 오전 중 정상 출고된 것으로 확인됩니다 .', '네 . 잘못 간 주소로 반품요청을 해드렸는데요 .', '아니요 방문 가능합니다 .', '넵확인 후 발송해드리겠습니다 .  배송료는 착불입니다 .', '제주도 추가 배송료 3000원입니다 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc0c3385-eb15-437b-834b-4ad8b9794b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문과 답변을 모두 포함한 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "882767fc-020a-42ed-a136-84f87a67ea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8110]\n",
      "종료 토큰 번호 : [8111]\n",
      "단어 집합의 크기 : 8112\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03a06a0c-f342-485e-86fc-fa0cdb9b4610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample question: [2339, 2699, 366, 63, 39, 553, 175, 209, 217, 95, 123, 140, 2464, 1692, 299, 4959, 63, 39, 875, 34, 248, 1]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6a9fce3-05fe-491e-b161-41a37dadc39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [2339, 2699, 366, 63, 39, 553, 175, 209, 217, 95, 123, 140, 2464, 1692, 299, 4959, 63, 39, 875, 34, 248, 1]\n",
      "기존 문장: 5만원 이상이라 무료 배송 주문인데 추가로 지금 더 주문하면 아까 주문건이랑 묶음으로 무료 배송 받을 수 있을까요 ?\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 decode() 테스트해보기\n",
    "\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eaa20ce-65d1-47a5-8b73-5d09fb4a3b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2339 ----> 5만원 \n",
      "2699 ----> 이상이\n",
      "366 ----> 라 \n",
      "63 ----> 무료 \n",
      "39 ----> 배송 \n",
      "553 ----> 주문\n",
      "175 ----> 인데 \n",
      "209 ----> 추가로 \n",
      "217 ----> 지금 \n",
      "95 ----> 더 \n",
      "123 ----> 주문하면 \n",
      "140 ----> 아\n",
      "2464 ----> 까 \n",
      "1692 ----> 주문건\n",
      "299 ----> 이랑 \n",
      "4959 ----> 묶음으로 \n",
      "63 ----> 무료 \n",
      "39 ----> 배송 \n",
      "875 ----> 받을 \n",
      "34 ----> 수 \n",
      "248 ----> 있을까요\n",
      "1 ---->  ?\n"
     ]
    }
   ],
   "source": [
    "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
    "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c384757-e368-4d1a-a4b5-f6845dfde0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89806d1d-702d-4bcd-9a30-d8fc2823542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47416381-d6d8-4a3b-9c12-c5784db3e6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (10000, 40)\n",
      "답변 데이터의 크기(shape) : (10000, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1733e0c4-a8a5-4ebe-ba0d-681cc15987a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8110  197  104  206  553   73 5747  303 1675 1398 1700 6717 7886 1526\n",
      "  240  553   26  339   41  129    1 8111    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8110  995 6403  952 2075 1168 1389  300 1406  200 1495 5975  370  427\n",
      "    2 8111    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 0번째 샘플을 임의로 출력\n",
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4d85abe-a833-46e3-9eff-dea45050fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기(Vocab size): 8112\n",
      "전체 샘플의 수(Number of samples): 10000\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기(Vocab size): {}'.format(VOCAB_SIZE))\n",
    "print('전체 샘플의 수(Number of samples): {}'.format(len(questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "152cc9f4-db79-4d23-afc5-81de1d304ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e396ae6-9b23-4008-9c4b-fa8a26bae28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8110  995 6403  952 2075 1168 1389  300 1406  200 1495 5975  370  427\n",
      "    2 8111    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8110  995 6403  952 2075 1168 1389  300 1406  200 1495 5975  370  427\n",
      "     2 8111    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[ 995 6403  952 2075 1168 1389  300 1406  200 1495 5975  370  427    2\n",
      "  8111    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2f2de6a-81e4-41e4-b8cb-dbd8f4bc1772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8112, 256)\n",
      "(1, 8112, 256)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyper-parameters\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92aa59eb-2f1c-4ffc-87f5-c4e852a5cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69827b73-da27-40ca-a650-334fbeea8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 116s 704ms/step - loss: 3.0063 - accuracy: 0.0201\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 111s 708ms/step - loss: 2.7051 - accuracy: 0.0322\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 110s 703ms/step - loss: 2.4355 - accuracy: 0.0516\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 112s 712ms/step - loss: 2.2878 - accuracy: 0.0586\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 110s 699ms/step - loss: 2.1745 - accuracy: 0.0659\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 108s 688ms/step - loss: 2.0597 - accuracy: 0.0744\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 107s 683ms/step - loss: 1.9482 - accuracy: 0.0806\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 108s 690ms/step - loss: 1.8428 - accuracy: 0.0867\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 108s 686ms/step - loss: 1.7382 - accuracy: 0.0939\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 110s 700ms/step - loss: 1.6322 - accuracy: 0.1011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d0010afd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EPOCHS = 50\n",
    "EPOCHS = 10\n",
    "\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ed4cc8d-58ba-4bd6-b0b5-482117b64545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1df0d431-bd9a-41ef-be59-e774591cfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c4bbc9e-aed0-4dd1-bb8b-ef4c825a9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 백령도 추가 배송비면 기본 2500원추가 3000원 총 5500원이 배송비인가요?\n",
      "Output: 네 무료 배송 맞습니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('백령도 추가 배송비면 기본 2500원추가 3000원 총 5500원이 배송비인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68d55b64-d216-4b9d-ab9a-2bb6693dbd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 제주도도 선료 있나요?\n",
      "Output: 제주도 추가 배송비 없습니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('제주도도 선료 있나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4000761-88aa-4fde-b979-7b889aefaf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 얼마 이상 무배인가요?\n",
      "Output: 네 무료 배송 맞습니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('얼마 이상 무배인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1647e769-4c96-4aa5-8e1d-4bd360590a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 8/16일요일까진 데 반납은 착불로 보내나요?\n",
      "Output: 네 무료 배송 맞습니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('8/16일요일까진 데 반납은 착불로 보내나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68bc01c7-4522-4383-897b-76ad4d97554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 빠른 배송 상품으로 주문했는데 제가 빠른 배송회원인데 왜 반송비 5,000원이 차감되서 환불될까요?\n",
      "Output: 네 무료 배송 맞습니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('빠른 배송 상품으로 주문했는데 제가 빠른 배송회원인데 왜 반송비 5,000원이 차감되서 환불될까요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31778840-4b19-4281-9205-2a3841a607c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 각각 두 번 주문, 결재하여 하나는 취소요청했어요 나머지 하나 주문만 발송되는 거 맞죠?\n",
      "Output: 네 맞습니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('각각 두 번 주문, 결재하여 하나는 취소요청했어요 나머지 하나 주문만 발송되는 거 맞죠?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdabda4d-1bb3-4667-839f-a186fcc3a252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 방문 수령해 도 택배비 부담해야 되나요?\n",
      "Output: 네 무료 배송 맞습니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('방문 수령해 도 택배비 부담해야 되나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76c1e4f8-e957-4879-a1a4-38c6a4171ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 10번 빨대리필 세트를 구매했는데 200ML 용 빨대리필 세트는 없나요?\n",
      "Output: 네 맞습니다 .  오늘 출고 예정입니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('10번 빨대리필 세트를 구매했는데 200ML 용 빨대리필 세트는 없나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12c2f721-cd9b-4224-bb72-a387b3998886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 바우처 결재가 오늘 왜 안 되나요?\n",
      "Output: 네 맞습니다 .  오늘 출고 예정입니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('바우처 결재가 오늘 왜 안 되나요?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
